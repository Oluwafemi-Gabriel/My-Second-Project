Data Cleaning Assignment
This repository is dedicated to showcasing the process and results of cleaning a dataset as part of an assignment on Data Cleaning Techniques. The goal of this project was to take a raw dataset, apply various data cleaning methods, and produce a clean, organized, and analysis-ready dataset. The cleaned dataset, along with the steps taken to achieve it, is shared here for reference and learning purposes.

About the Dataset
The original datasets, were provided as part of the assignment. It contained raw data that required cleaning and organization to make it usable for further analysis. The dataset included various columns with text, numerical, and categorical data, some of which had inconsistencies, missing values, and duplicates.

Data Cleaning Process
The following steps were taken to clean and prepare the dataset:

1. Sorting and Filtering
The dataset was first sorted and filtered to better organize the data. Sorting was applied to specific columns (e.g., dates, categories, or numerical values) to arrange the data in a logical order. Filtering helped isolate specific subsets of data for closer inspection and cleaning.

2. Conditional Formatting
Conditional formatting was applied to visually highlight specific values in the dataset. For example:
Values above or below a certain threshold were highlighted to identify outliers or anomalies.
Duplicate or unique values were color-coded for easier identification.

3. Handling Missing Values
Missing values in the dataset were addressed in two ways:
Filling in missing data: Where appropriate, missing values were filled in using logical assumptions or calculations.
Removing incomplete rows: In cases where missing data could not be reasonably filled, the corresponding rows were removed to ensure the integrity of the dataset.

4. Text Data Cleaning
Text functions such as LEFT, RIGHT, MID, and CONCATENATE were used to clean and manipulate text data. For example:
Extracting specific parts of strings (e.g., first names, last names, or codes) using LEFT, RIGHT, and MID.
Combining text from multiple columns into a single column using CONCATENATE.

5. Removing Duplicates
Duplicate rows were identified and removed using Excelâ€™s Remove Duplicates feature. This ensured that the dataset contained only unique and relevant entries.

6. Saving the Cleaned Dataset
After completing the cleaning process, the dataset was saved as Cleaned_Data_Ibikunle Oluwafemi Gabriel.xlsx,. This file represents the final, cleaned version of the dataset, ready for analysis or further use.

Tools Used
The following tools were used to complete this assignment:

Microsoft Excel:
Excel was the primary tool used for data cleaning. Its features, such as sorting, filtering, conditional formatting, and text functions, were instrumental in organizing and cleaning the dataset.

GitHub:
GitHub was used for version control and sharing the cleaned dataset. By uploading the dataset and documenting the process in this repository, the work is made accessible and transparent for others to review and learn from.
